{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tensorflow Basics \n",
    "\n",
    "Tensorflow is a graph-based numerical computation library. Complex mathematical operations are described in a graph-like data structure, where nodes in the graph represent the mathematical operations, and connections between nodes represent the flow of data from operation to operation. In Tensorflow, these data are held as **tensor** objects, which is just a generalization of a matrix. \n",
    "\n",
    "![tf-graph](https://www.tensorflow.org/images/getting_started_add.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We will be using the Python API to access Tensorflow's data structures and functions, which are implemented in a C++ backend. \n",
    "\n",
    "A Tensorflow program can be divided into two essential parts: \n",
    "\n",
    "1. Building a computational graph\n",
    "\n",
    "2. Launching and running the computational graph\n",
    "\n",
    "A **computational graph** is just a series of mathematical operations defined on some data, which we can easily create in Tensorflow. Let's create our first tensorflow program!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import our essential libraries\n",
    "import tensorflow as tf # we can access tensorflow with \"tf\" now\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(3.0)\n",
    "b = tf.constant(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Printing out the nodes does not produce the values that you may have expected. This is because Tensorflow only evaluates variables and runs operations in the context of a `session`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "print(sess.run([a, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's learn a little more about Tensorflow's graph-based computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(3.0)\n",
    "b = tf.constant(4.0)\n",
    "s = tf.multiply(a, b) # shortcut is just a * b\n",
    "print(sess.run(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Exercise: Create constants and use Tensorflow's add, multiply, and subtract functions to evaluate: \n",
    "                8(2 + 3) - 6( 4 + 6). \n",
    "\n",
    "Think about how you can express this computation as a graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: create variables a, b, c, s, and d that correspond to the numerical values given above.\n",
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = tf.constant(8.0)\n",
    "s = tf.constant(6.0)\n",
    "d = tf.constant(4.0)\n",
    "\n",
    "# TODO: use Tensorflow to express the above function\n",
    "a_plus_b = tf.add(a, b)\n",
    "m = tf.multiply(a_plus_b, c)\n",
    "n = tf.add(d, s)\n",
    "sub = -tf.multiply(s, n)\n",
    "ans = tf.add(m, sub)\n",
    "\n",
    "# TODO: run the function with sess.run() in a session and obtain the answer.\n",
    "sess.run(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Placeholders and Variables\n",
    "\n",
    "What we've learned so far is pretty cool, but it's not particularly useful. We want to be able to run our computations on arbitrary data. And thus we must learn about placeholders and variables. \n",
    "\n",
    "A ** placeholder ** in Tensorflow is just a promise to provide some value at a later time. We can define a series of computations without knowing the actual data the computation will run on. Think of these as values which we will define later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sess.run(adder) # what will happen if we run this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: fix the above error by specifying the values to be passed into the function.\n",
    "sess.run(adder, feed_dict = {a: 4.0, b: 5.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's continue learning about placeholders, and see how they work with constants to define mathematical functions. While doing this, we'll also learn about the numpy library and the matplotlib library, which turn out to be essential machine learning tools for doing numerical comptutation and creating plots of our data. Say we want to evaluate the following function: $ 5 \\log(x) + e^x $. \n",
    "\n",
    "For the sake of using Tensorflow, let's see how we can model this function as a comptuational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: model the above function as a computational graph\n",
    "x = tf.placeholder(tf.float32)\n",
    "func = 5 * tf.log(x) + tf.exp(x) # tf.exp(x) is equivalent to tf.pow(e, x) where e is Euler's number (2.718...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: print the output of the function when it is run with the argument 10. \n",
    "print(sess.run(func, feed_dict = {x: 10}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Say we want to run this function for all inputs in the range [1, 10), and display a plot of the outputs versus the inputs. We can accomplish this quickly using the tools that the numpy and matplotlib libraries give us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_list = list(np.arange(1, 10))\n",
    "# TODO: run the function from above for each value in the input_list, and save the output to another list output_list.\n",
    "output_list = []\n",
    "for i in input_list:\n",
    "    output = sess.run(func, feed_dict = {x: i})\n",
    "    output_list.append(output)\n",
    "print(output_list)\n",
    "# alternatively, Python supports \"list comprehensions\", and we can write the above code in one line:\n",
    "output_list = [sess.run(func, feed_dict = {x: i}) for i in input_list]\n",
    "print(output_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, we can use matplotlib to plot the above data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(input_list, output_list) # plot input_list on x-axis, output_list on y-axis\n",
    "plt.title('Some Function') # optionally specify a title for the plot\n",
    "plt.xlabel('Inputs') # optionally specify a title for the x-axis\n",
    "plt.ylabel('Function Output') #optionally specify a title for the y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we want to be able to create **variables** as a part of our computational graph. Previously, when we defined a value with Tensorflow, it's value couldn't really be changed - it was specified as a `tf.constant` or specified once as an argument into `feed_dict`. As Adit discussed, with machine learning we want to be able to change the weights in our function over time as we train our model. The `tf.Variable` type helps us accomplish this!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating Variables in Tensorflow\n",
    "\n",
    "One way to create variables in tensorflow is with the ``` tf.Variable() ``` API. When creating variables, we usually want to provide a method of ** initializing ** the variable, and usually also want to mention the ** dimensionality ** of the variable (ie, do we wish to create a constant? Or do we wish to create a vector or matrix of a certain dimension?)\n",
    "\n",
    "With Tensorflow, we need to explicitly ** intialize ** all of our variable by registering a variable initailizer, and running it within our session. This may sound a little complicated, but its just 2 lines of code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.constant(0.1, shape = [10,1])) # create a variable with information on how to initialize it and its dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Placeholders (tensors that we've promised to give data to later) can also take on arbitrary shapes. Of course, if you set a placeholder with a certain dimensionality, it will later expect data of that dimensionality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = [1, 10]) # think of this as one training example that has 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mat_mul = tf.matmul(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = np.arange(10).reshape((1,10)) # 0,1,2,3...10 reshaped into a 1 * 10 matrix\n",
    "\n",
    "# initialize our variables\n",
    "init = tf.global_variables_initializer() # the variable initializer\n",
    "sess.run(init)\n",
    "sess.run(mat_mul, feed_dict = {x: data}) # can you predict the output? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise\n",
    "Let's create a function that takes in a set of 5 vectors each with dimensionality 10, and multiplies it with a matrix W of dimensionality $ 10 * 5 $. What would we need to change in the code above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: define a variable W_matrix to be a variable that is initialized with the constant 0.1, but has dimensionality 10 * 5\n",
    "W_matrix = tf.Variable(tf.constant(0.1, shape = [10, 5]))\n",
    "# TODO: define a variable x_matrix to be a placeholder of shape 5 * 10.\n",
    "x_matrix = tf.placeholder(tf.float32, shape = [5, 10])\n",
    "# TODO: redefine the above mat_mul operation to use W_matrix and x_matrix.\n",
    "mat_mul = tf.matmul(x_matrix, W_matrix)\n",
    "\n",
    "# TODO: define a new variable initializer, and run it. \n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: create 50 arbitrary data points, and reshape them into a 5 * 10 matrix, so we can feed this into x as a placeholder.\n",
    "data = np.arange(50).reshape((5, 10))\n",
    "# TODO: run the function with sess.run(), and don't forget to pass in the argument for x_matrix!\n",
    "ans = sess.run(mat_mul, feed_dict = {x_matrix: data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Recap\n",
    "We've learned the very basics of tensorflow: how to represent the computational graphs, use placeholders to input data later, and create variables. It turns out that with these tools and a little knowledge about optimization in Tensorflow, we can easily implement many machine learning models. Let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Linear Regression\n",
    "\n",
    "Linear regression can be thought of as the \"hello world\" of machine learning. It's relatively straigthforward to implement once you understand it, yet (unlike a simple \"hello world\" app) is powerful enough to have signficant use in industry. Let's take a look at the linear regression problem. \n",
    "\n",
    "We have some (input, output) pairs which we denote as $ (x_i, y_i) $ and we have $n$ of these, so $i \\in [1...n]$. We want to learn a function $f: x \\rightarrow{} y$ that maps inputs to outputs. \n",
    "\n",
    "Crucially, we want to learn the function $ f $ such that $ f $ generalizes well to **unseen** data. We can easily create a function $ f $ that always returns the correct answer on data we've seen before (data in our training set) - can you guess what that function would look like, and why it would be essentially worthless for data we haven't seen before? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Today's Dataset\n",
    "\n",
    "We'll be using the [Boston house prices dataset](http://lib.stat.cmu.edu/datasets/boston). This dataset has 500 training examples, each with 13 features describing various attributes of the home, and a target associated with the example, giving the value of the home in thousands of dollars. \n",
    "\n",
    "Each of the 13 features denotes some quality or quantity regarding the house or the surrounding area. A few examples of the different features included in the dataset include the area's **crime rate**, the **number of rooms** in the house, the ** distance from the house to popular Boston locations**, and the average **student to teacher ratio** in nearby schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from boston_data_wrapper import get_data\n",
    "X_train, X_test, y_train, y_test = get_data()\n",
    "\n",
    "# TODO: what are the dimensionalities of our training and testing datasets and targets? \n",
    "print(\",\".join([str(t.shape) for t in (X_train, X_test, y_train, y_test)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we've seen, we have 506 data points which we've split into two sets, `X_train` and `X_test`. We took 70% of the total data as training data (hence `X_train`), and 30% of the data as testing data (hence `X_test`). This is a popular split in machine learning - we always want to hold out some of our given data and not use it while training, so we have some data on which to evaluate the performance of our model.\n",
    "\n",
    "The names `y_train` and `y_test` have a one-to-one correspondence to the values in `X_train` and `X_test`. In particular, for each house `X_train[i]`, the value for the home is given by `y_train[i]`.\n",
    "\n",
    "To get more familiar with our dataset, let's try to visualize how some of the features relate to the price of the house. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get the crime rates and prices\n",
    "crime_rates, prices = [X_train[i][0] for i in range(X_train.shape[0])], y_train.tolist()\n",
    "# student-teacher ratio is the 10th feature\n",
    "student_teacher_ratios = [X_train[i][10] for i in range(X_train.shape[0])]\n",
    "# number of roots is the 5th feature\n",
    "rooms = [X_train[i][5] for i in range(X_train.shape[0])]\n",
    "\n",
    "plt.scatter(crime_rates, prices)\n",
    "plt.xlabel('Crime Rate')\n",
    "plt.ylabel('House Price')\n",
    "plt.title('Crime Rates vs House Price')\n",
    "plt.figure()\n",
    "plt.scatter(student_teacher_ratios, prices)\n",
    "plt.xlabel('Student Teacher Ratio')\n",
    "plt.ylabel('House Price')\n",
    "plt.title('Student teacher ratios vs House Price')\n",
    "plt.figure()\n",
    "plt.scatter(rooms, prices)\n",
    "plt.xlabel('Rooms')\n",
    "plt.ylabel('House Price')\n",
    "plt.title('Number of rooms vs House Price')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Linear Regression: An overview\n",
    "\n",
    "As discussed in the slides, we can teach a computer how to predict housing prices based on data. In order to do this, we will create a linear model in many dimensions (specifically, 13, the number of features in our dataset). \n",
    "\n",
    "Our goal is to learn a function $ f: x \\rightarrow{} y$ that maps information about a house to the house's price prediction. With linear regression, our function $f$ is just a ** linear combination ** of our inputs. That means our output is just the sum of our inputs, but each of our inputs are weighted by some value: \n",
    "\n",
    "$$f(x) = w_1 x_1 + w_2 x_2 + ... w_{13}x_{13} + b = \\sum_{j=1}^{13} w_j x_j + b$$\n",
    "\n",
    "Next, we will initialize this linear model with initially random weights. As a result, our model won't be able to predict house prices very well at all. Learning is the process of adjusting these parameters so that our model's accuracy increases. In order to do this, we need to mathematically quantify how \"bad\" our model is currently. We can do this by calculating how off each prediction is from the actual value: \n",
    "\n",
    "$$ L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - f(x_i))^2 $$\n",
    "\n",
    "If we take the derivative of this function with respect to each of the weights $w$, we will know how much to \"adjust\" each weight $w$ by in order to make our function more accurate. This is an algorithm called ** gradient descent **. \n",
    "\n",
    "If you know some multivariable calculus, you can determine that the derivative with respect to the $i$th weight is $$ \\frac{dL}{dw_i} = \\frac{-2}{N} \\sum_{i=1}^{N} (y_i - f(x_i))x_i $$\n",
    "\n",
    "This is getting a little abstract - lets move on to actually coding up this model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: create placeholders for X and y, our features and tagets, respectively.\n",
    "X = tf.placeholder(tf.float32, shape = [None, 13])\n",
    "y = tf.placeholder(tf.float32, shape = [None,1])\n",
    "\n",
    "# TODO: create variables for W and b, and initialize them with constants.\n",
    "W = tf.Variable(tf.constant(0.1, shape = [13,1 ]))\n",
    "b = tf.Variable(tf.constant(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: use Tensorflow to write out the linear regression model and assign it to a variable y_pred.\n",
    "# y_pred = ...\n",
    "y_pred = tf.matmul(X, W) + b\n",
    "loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate = .5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "initial_loss = loss.eval(feed_dict = {X: X_train, y: y_train})\n",
    "print(\"initial loss: {}\".format(initial_loss))\n",
    "for i in range(5000):\n",
    "    # TODO: run the optimization step with the training data passed in.\n",
    "    sess.run(opt, feed_dict = {X: X_train, y: y_train})\n",
    "    if i % 100 == 0:\n",
    "        # TODO: print the current error of the model so we can know how the model is doing while it is training\n",
    "        print(\"current loss: {}\".format(loss.eval(feed_dict = {X: X_train, y: y_train})))\n",
    "\n",
    "# TODO: evalute and print the final loss on the training and testing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's evaluate our model and see how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data, targets = X_test, y_test\n",
    "predictions = sess.run(y_pred, feed_dict = {X: data})\n",
    "predictions = predictions.flatten()\n",
    "targets = targets.reshape((152))\n",
    "\n",
    "# lets take a look at some predictions\n",
    "for i in range(10):\n",
    "    randint = np.random.randint(0, 152)\n",
    "    pred = predictions[randint]\n",
    "    actual = targets[randint]\n",
    "    print(\"prediction: {}, actual was: {}\".format(pred, actual))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's plot the absolute differences as a function of the actual price. This will give us some intution around where our model is not so good - does it work equally well for all ranges of house prices, or does it perform worse depending on the actual house price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "diffs = abs(targets - predictions)\n",
    "avg_diffs = np.mean(diffs)\n",
    "avg_houseprice = np.mean(targets)\n",
    "plt.xlabel('Home price values')\n",
    "plt.ylabel('Diff btwn targets and functions')\n",
    "plt.scatter(targets, diffs)\n",
    "plt.show()\n",
    "print(\"average absolute difference: {}\".format(avg_diffs * 1000))\n",
    "print(\"average house price: {}\".format(avg_houseprice * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our model seems to do okay with lower and averaged price houses, but appears to do terribly with higher-priced houses. Think about why this may be. It's always important to consider the data that you used to train your model. In particular, it might be likely that our dataset didn't have many examples of highly priced houses, so our model may have not learned how to predict prices for them. What's cool about data science and machine learning is that we can easily test this theory. \n",
    "\n",
    "All of the prices in the dataset are between 0 and 50 (in thousands of dollars). We can count up how many examples we have for houses between 0 and $10, 000, between $10,000 and $20,000, and so on. This will let us examine if there are any imbalances with respect to the house prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "price_buckets = [0, 10, 20, 30, 40, 50]\n",
    "limits = dict(zip(price_buckets, [0  for _ in range(len(price_buckets))]))\n",
    "print(limits)\n",
    "for price in targets:\n",
    "    limits[int(price/10) * 10]+=1\n",
    "\n",
    "for k, v in sorted(limits.items()):\n",
    "    print(\"{} : {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercises\n",
    "\n",
    "- As we have seen, our model is not very accurate for very highly-priced houses. How many higher-priced houses be different than lower-priced houses, and what did our model not capture about them? \n",
    "\n",
    "\n",
    "- Investigate the need for a bias unit in our linear model. How can you adjust our current model to not have the bias unit (hint: just remove it). What happens to the model if the bias unit is removed? Why is having a bias unit important in machine learning models?\n",
    "\n",
    "\n",
    "- Investigate different learning rates other than 0.5. Anything under 0.5 should work well, but you may have to play around with the number of iterations. Why is this - why do some learning rates require more iterations while others do not? Try learning rates greater than 0.5, and observe what happens. Why do you think this is? What do you think are some good guidelines to pick an optimal learning rate? \n",
    "\n",
    "\n",
    "\n",
    "- Try ```Polynomial Regression```. This involves generating additional features that are combinations of the original features. In higher-dimensional space, the house price and newly generated features may be linear with respect to each other. To do this, you'll have to use the ```sklearn.preprocessing.PolynomialFeatures``` library to generate new features. Instead of 13, you'll also have to update your model to take in the new number of features you have created. \n",
    "\n",
    "\n",
    "- Do something interesting: If you have any ideas to change the model up or improve accuracy in some way, fork this repository and make your changes. Then post it on the AI at UCLA page for us to see! Also, don't forget to create a pull request on our github if you want your change merged into our tutorials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Thank you for attending! Please fill out our [feedback form](http://tinyurl.com/acmai123) so we can produce even better content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
